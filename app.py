"""
å¤§å­¦ç”Ÿå¿ƒç†åˆ†ææ•°å­—äººä»£ç† - ä¸»æœåŠ¡å™¨
=====================================

æœ¬æ¨¡å—æä¾›åŸºäº Flask çš„ Web æœåŠ¡ï¼Œé›†æˆä»¥ä¸‹åŠŸèƒ½ï¼š
1. DeepSeek API å¿ƒç†å’¨è¯¢æœåŠ¡
2. DeepFace é¢éƒ¨è¡¨æƒ…è¯†åˆ«
3. å¯¹è¯å†å²ç®¡ç†
4. RESTful API æ¥å£

ä½œè€…: SRTP é¡¹ç›®ç»„
ç‰ˆæœ¬: 2.0
"""

import os
import base64
import logging
import datetime
import subprocess
import uuid
import glob
from typing import Dict, Any, Optional

import cv2
import numpy as np
import requests
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS

# ==================== æ—¥å¿—é…ç½® ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== DeepFace å¯¼å…¥ ====================
try:
    from deepface import DeepFace
    DEEPFACE_AVAILABLE = True
    logger.info("DeepFace åº“åŠ è½½æˆåŠŸ")
except ImportError:
    DEEPFACE_AVAILABLE = False
    logger.warning("DeepFace åº“æœªå®‰è£…ï¼Œè¡¨æƒ…è¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: pip install deepface")

# ==================== Flask åº”ç”¨åˆå§‹åŒ– ====================
app = Flask(__name__, static_folder='.', static_url_path='')
CORS(app)  # å¯ç”¨è·¨åŸŸæ”¯æŒ

# ==================== é…ç½®å¸¸é‡ ====================
# DeepSeek API é…ç½®ï¼ˆå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨å¯†é’¥ï¼‰
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-215440b00f1d426fb21a2f11eef6cf02")
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"

# TTS API é…ç½® (SiliconFlow)
TTS_API_URL = "https://api.siliconflow.cn/v1/audio/speech"
TTS_API_TOKEN = "sk-lvtuhfndddcmdyvnjtbzjuobfoewylsnqaqwfsnuznpilhkp"

# SadTalker é…ç½®
SADTALKER_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "SadTalker")
SADTALKER_IMAGE = os.path.join(SADTALKER_DIR, "my_photo.png")  # æ•°å­—äººå›¾ç‰‡
SADTALKER_OUTPUT_DIR = os.path.join(SADTALKER_DIR, "results")
AUDIO_OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "audio_output")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(AUDIO_OUTPUT_DIR, exist_ok=True)
os.makedirs(SADTALKER_OUTPUT_DIR, exist_ok=True)

# æƒ…ç»ªæ˜ å°„è¡¨
EMOTION_MAP = {
    'angry':    {'icon': 'ğŸ˜ ', 'name': 'ç”Ÿæ°”', 'context': 'æœ‰äº›ç”Ÿæ°”'},
    'disgust':  {'icon': 'ğŸ¤¢', 'name': 'åŒæ¶', 'context': 'æœ‰äº›åæ„Ÿ'},
    'fear':     {'icon': 'ğŸ˜¨', 'name': 'ææƒ§', 'context': 'æ„Ÿåˆ°ç´§å¼ '},
    'happy':    {'icon': 'ğŸ˜Š', 'name': 'å¼€å¿ƒ', 'context': 'çœ‹èµ·æ¥å¿ƒæƒ…ä¸é”™'},
    'sad':      {'icon': 'ğŸ˜¢', 'name': 'æ‚²ä¼¤', 'context': 'æƒ…ç»ªæœ‰äº›ä½è½'},
    'surprise': {'icon': 'ğŸ˜²', 'name': 'æƒŠè®¶', 'context': 'æœ‰äº›æƒŠè®¶'},
    'neutral':  {'icon': 'ğŸ˜', 'name': 'å¹³é™', 'context': 'æƒ…ç»ªå¹³ç¨³'}
}

# é»˜è®¤æƒ…ç»ªåˆ†æ•°ï¼ˆå½“æ£€æµ‹å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
DEFAULT_EMOTION_SCORES = {
    'angry': 0.0, 'disgust': 0.0, 'fear': 0.0,
    'happy': 0.0, 'sad': 0.0, 'surprise': 0.0, 'neutral': 100.0
}

# å¯¹è¯å†å²ï¼ˆå…¨å±€å˜é‡ï¼‰
conversation_history: list = []


# ==================== å¿ƒç†åˆ†æä»£ç†ç±» ====================
class PsychologicalAgent:
    """
    å¿ƒç†åˆ†æä»£ç†ç±»

    è´Ÿè´£ä¸ DeepSeek API äº¤äº’ï¼Œæä¾›å¿ƒç†å’¨è¯¢æœåŠ¡ã€‚
    æ”¯æŒå¤šè½®å¯¹è¯ï¼Œç»“åˆç”¨æˆ·æƒ…ç»ªçŠ¶æ€ç”Ÿæˆä¸ªæ€§åŒ–å›å¤ã€‚
    """

    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ–å¿ƒç†åˆ†æä»£ç†

        Args:
            api_key: DeepSeek API å¯†é’¥
        """
        self.api_key = api_key
        self.api_url = DEEPSEEK_API_URL

    def _build_system_prompt(self, emotion: str) -> str:
        """
        æ„å»ºç³»ç»Ÿæç¤ºè¯

        Args:
            emotion: æ£€æµ‹åˆ°çš„æƒ…ç»ªç±»å‹

        Returns:
            åŒ…å«æƒ…ç»ªä¸Šä¸‹æ–‡çš„ç³»ç»Ÿæç¤ºè¯
        """
        emotion_info = EMOTION_MAP.get(emotion, EMOTION_MAP['neutral'])
        emotion_context = emotion_info['context']

        return f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„å¤§å­¦å¿ƒç†å¥åº·é¡¾é—®ï¼Œä¸“é—¨å¸®åŠ©å¤§å­¦ç”Ÿè§£å†³å¿ƒç†é—®é¢˜ã€‚

é‡è¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
- ç³»ç»Ÿæ£€æµ‹åˆ°ç”¨æˆ·å½“å‰çš„æƒ…ç»ªçŠ¶æ€ä¸ºï¼š{emotion} ({emotion_context})
- è¿™ä¸ªæƒ…ç»ªä¿¡æ¯æ¥è‡ªå®æ—¶é¢éƒ¨è¡¨æƒ…åˆ†æ
- è¯·ç»“åˆç”¨æˆ·æè¿°çš„æ–‡å­—å†…å®¹å’Œæ£€æµ‹åˆ°çš„æƒ…ç»ªçŠ¶æ€ï¼Œæä¾›æ›´ç²¾å‡†çš„å¿ƒç†åˆ†æ

ä½ çš„èŒè´£ï¼š
1. åˆ†æå­¦ç”Ÿçš„å¿ƒç†çŠ¶æ€å’Œæƒ…ç»ªé—®é¢˜
2. æä¾›ä¸“ä¸šã€æ¸©æš–çš„å¿ƒç†æ”¯æŒå’Œå»ºè®®
3. è¯†åˆ«å±æœºæƒ…å†µå¹¶ç»™å‡ºé€‚å½“å»ºè®®
4. ç”¨åŒç†å¿ƒå’Œç†è§£æ¥å›åº”ç”¨æˆ·

è¯·ä»¥æ¸©æš–ã€ä¸“ä¸šã€æ”¯æŒæ€§çš„è¯­æ°”å›åº”ï¼Œé¿å…ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€æä¾›å»ºè®®ã€‚"""

    def analyze(self, user_input: str, emotion: str = "neutral") -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå¿ƒç†å’¨è¯¢å›å¤

        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
            emotion: æ£€æµ‹åˆ°çš„æƒ…ç»ªç±»å‹ï¼Œé»˜è®¤ä¸º neutral

        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸ï¼ŒåŒ…æ‹¬ successã€responseã€model_source ç­‰å­—æ®µ
        """
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": self._build_system_prompt(emotion)}]

            # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆæœ€å¤š 3 è½®ï¼Œå³ 6 æ¡æ¶ˆæ¯ï¼‰
            if conversation_history:
                messages.extend(conversation_history[-6:])

            messages.append({"role": "user", "content": user_input})

            logger.info(f"è°ƒç”¨ DeepSeek API - æƒ…ç»ª: {emotion}, è¾“å…¥: {user_input[:50]}...")

            # è°ƒç”¨ API
            response = requests.post(
                self.api_url,
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}"
                },
                json={
                    "model": "deepseek-chat",
                    "messages": messages,
                    "temperature": 0.7,  # æ§åˆ¶å›å¤çš„éšæœºæ€§
                    "max_tokens": 800,   # é™åˆ¶å›å¤é•¿åº¦
                    "stream": False
                },
                timeout=30
            )

            # å¤„ç†å“åº”
            if response.status_code == 200:
                result = response.json()
                assistant_response = result['choices'][0]['message']['content']

                # æ›´æ–°å¯¹è¯å†å²
                self._update_history(user_input, assistant_response)

                return {
                    "success": True,
                    "response": assistant_response,
                    "model_source": "deepseek_api"
                }
            else:
                logger.error(f"API è°ƒç”¨å¤±è´¥: {response.status_code} - {response.text[:200]}")
                return {
                    "success": False,
                    "error": f"API é”™è¯¯: {response.status_code}",
                    "response": "æŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
                }

        except requests.exceptions.Timeout:
            logger.error("API è¯·æ±‚è¶…æ—¶")
            return {
                "success": False,
                "error": "è¯·æ±‚è¶…æ—¶",
                "response": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ã€‚"
            }
        except Exception as e:
            logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "response": "ç³»ç»Ÿæš‚æ—¶å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
            }

    def _update_history(self, user_input: str, assistant_response: str) -> None:
        """
        æ›´æ–°å¯¹è¯å†å²

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            assistant_response: AI å›å¤
        """
        conversation_history.append({"role": "user", "content": user_input})
        conversation_history.append({"role": "assistant", "content": assistant_response})

        # é™åˆ¶å†å²è®°å½•é•¿åº¦ï¼ˆä¿ç•™æœ€è¿‘ 10 æ¡ï¼‰
        if len(conversation_history) > 10:
            conversation_history[:] = conversation_history[-10:]


# ==================== è¡¨æƒ…è¯†åˆ«æ¨¡å— ====================
def analyze_emotion_from_image(image_data: str) -> Dict[str, Any]:
    """
    ä» Base64 ç¼–ç çš„å›¾åƒä¸­åˆ†æé¢éƒ¨è¡¨æƒ…

    Args:
        image_data: Base64 ç¼–ç çš„å›¾åƒæ•°æ®

    Returns:
        åŒ…å«æƒ…ç»ªåˆ†æç»“æœçš„å­—å…¸ï¼ŒåŒ…æ‹¬ dominant_emotionã€emotion_scoresã€face_detected
    """
    # æ£€æŸ¥ DeepFace æ˜¯å¦å¯ç”¨
    if not DEEPFACE_AVAILABLE:
        logger.warning("DeepFace åº“ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤æƒ…ç»ª")
        return {
            "dominant_emotion": "neutral",
            "emotion_scores": DEFAULT_EMOTION_SCORES.copy(),
            "face_detected": False
        }

    logger.info("å¼€å§‹ DeepFace è¡¨æƒ…åˆ†æ...")

    try:
        # è§£ç  Base64 å›¾åƒ
        if ',' in image_data:
            image_data = image_data.split(',')[1]

        img_bytes = base64.b64decode(image_data)
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if img is None:
            logger.warning("å›¾åƒè§£ç å¤±è´¥")
            return {
                "dominant_emotion": "neutral",
                "emotion_scores": DEFAULT_EMOTION_SCORES.copy(),
                "face_detected": False
            }

        # ä½¿ç”¨ DeepFace åˆ†æè¡¨æƒ…
        analysis = DeepFace.analyze(
            img,
            actions=['emotion'],
            detector_backend='opencv',  # ä½¿ç”¨ OpenCV æ£€æµ‹å™¨ï¼ˆé€Ÿåº¦å¿«ï¼‰
            enforce_detection=False,    # ä¸å¼ºåˆ¶æ£€æµ‹åˆ°äººè„¸
            silent=True                 # é™é»˜æ¨¡å¼
        )

        if not analysis:
            logger.warning("DeepFace è¿”å›ç©ºç»“æœ")
            return {
                "dominant_emotion": "neutral",
                "emotion_scores": DEFAULT_EMOTION_SCORES.copy(),
                "face_detected": False
            }

        # æå–ç»“æœ
        dominant_emotion = analysis[0]['dominant_emotion']
        emotion_scores = analysis[0]['emotion']

        # æ£€æŸ¥æ˜¯å¦çœŸæ­£æ£€æµ‹åˆ°äººè„¸ï¼ˆé€šè¿‡æ£€æŸ¥ face_confidence æˆ– regionï¼‰
        face_region = analysis[0].get('region', {})
        face_confidence = analysis[0].get('face_confidence', 0)

        # è®°å½•è¯¦ç»†çš„åˆ†æç»“æœç”¨äºè°ƒè¯•
        logger.info(f"è¡¨æƒ…åˆ†æç»“æœ: dominant={dominant_emotion}, scores={emotion_scores}")
        logger.info(f"äººè„¸åŒºåŸŸ: {face_region}, ç½®ä¿¡åº¦: {face_confidence}")

        # è½¬æ¢ä¸º Python float ç±»å‹ï¼ˆé¿å… JSON åºåˆ—åŒ–é—®é¢˜ï¼‰
        converted_scores = {k: float(v) for k, v in emotion_scores.items()}

        # åˆ¤æ–­æ˜¯å¦çœŸæ­£æ£€æµ‹åˆ°äººè„¸
        # å¦‚æœäººè„¸åŒºåŸŸå¤ªå°æˆ–ç½®ä¿¡åº¦å¤ªä½ï¼Œå¯èƒ½æ˜¯è¯¯æ£€
        face_detected = True
        if face_region:
            w = face_region.get('w', 0)
            h = face_region.get('h', 0)
            # å¦‚æœæ£€æµ‹åˆ°çš„äººè„¸åŒºåŸŸå¤ªå°ï¼ˆå°äº50x50åƒç´ ï¼‰ï¼Œè®¤ä¸ºæ²¡æœ‰æ£€æµ‹åˆ°æœ‰æ•ˆäººè„¸
            if w < 50 or h < 50:
                logger.warning(f"æ£€æµ‹åˆ°çš„äººè„¸åŒºåŸŸå¤ªå°: {w}x{h}")
                face_detected = False

        return {
            "dominant_emotion": dominant_emotion,
            "emotion_scores": converted_scores,
            "face_detected": face_detected
        }

    except Exception as e:
        logger.warning(f"è¡¨æƒ…åˆ†æå¤±è´¥: {str(e)[:100]}")
        return {
            "dominant_emotion": "neutral",
            "emotion_scores": DEFAULT_EMOTION_SCORES.copy(),
            "face_detected": False
        }


def generate_fallback_response(user_input: str, emotion: str) -> Dict[str, Any]:
    """
    ç”Ÿæˆå¤‡é€‰å›å¤ï¼ˆå½“ API ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        emotion: æ£€æµ‹åˆ°çš„æƒ…ç»ª

    Returns:
        åŒ…å«å¤‡é€‰å›å¤çš„å­—å…¸
    """
    emotion_info = EMOTION_MAP.get(emotion, EMOTION_MAP['neutral'])
    emotion_prefix = f"{emotion_info['context']}ï¼Œ" if emotion != 'neutral' else ""

    # å…³é”®è¯åŒ¹é…å›å¤
    keyword_responses = {
        'å‹åŠ›': f"{emotion_prefix}å¯¹äºå‹åŠ›é—®é¢˜ï¼Œå»ºè®®ï¼š<br>1. æ·±å‘¼å¸æ”¾æ¾ç»ƒä¹ <br>2. åˆç†å®‰æ’æ—¶é—´å’Œä¼˜å…ˆçº§<br>3. é€‚é‡è¿åŠ¨é‡Šæ”¾å‹åŠ›<br>4. ä¸æœ‹å‹æˆ–å®¶äººå€¾è¯‰",
        'ç„¦è™‘': f"{emotion_prefix}åº”å¯¹ç„¦è™‘çš„æ–¹æ³•ï¼š<br>1. æ­£å¿µå†¥æƒ³ç»ƒä¹ <br>2. å†™ä¸‹æ‹…å¿§äº‹é¡¹<br>3. æ¸è¿›å¼è‚Œè‚‰æ”¾æ¾<br>4. ä¿æŒè§„å¾‹ä½œæ¯",
        'å¤±çœ ': f"{emotion_prefix}æ”¹å–„ç¡çœ çš„å»ºè®®ï¼š<br>1. ç¡å‰1å°æ—¶ä¸ä½¿ç”¨ç”µå­è®¾å¤‡<br>2. åˆ›é€ èˆ’é€‚çš„ç¡çœ ç¯å¢ƒ<br>3. ä¿æŒè§„å¾‹çš„ä½œæ¯æ—¶é—´<br>4. é¿å…ç¡å‰æ‘„å…¥å’–å•¡å› ",
        'æŠ‘éƒ': f"{emotion_prefix}å¦‚æœæŒç»­æƒ…ç»ªä½è½ï¼š<br>1. å¯»æ±‚ä¸“ä¸šå¿ƒç†å’¨è¯¢<br>2. ä¿æŒé€‚åº¦çš„ç¤¾äº¤æ´»åŠ¨<br>3. åšæŒé€‚é‡è¿åŠ¨<br>4. ç»™è‡ªå·±ä¸€äº›æ—¶é—´å’Œè€å¿ƒ",
        'å­¦ä¹ ': f"{emotion_prefix}å­¦ä¹ å‹åŠ›ç®¡ç†ï¼š<br>1. åˆ¶å®šåˆç†çš„å­¦ä¹ è®¡åˆ’<br>2. ä½¿ç”¨ç•ªèŒ„å·¥ä½œæ³•æé«˜æ•ˆç‡<br>3. ä¿è¯å……è¶³çš„ä¼‘æ¯æ—¶é—´<br>4. ä¸åŒå­¦äº¤æµå­¦ä¹ å¿ƒå¾—"
    }

    # æŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯
    for keyword, response in keyword_responses.items():
        if keyword in user_input.lower():
            return {
                "success": True,
                "response": response,
                "detected_emotion": emotion,
                "model_source": "fallback_system",
                "timestamp": datetime.datetime.now().isoformat()
            }

    # é€šç”¨å›å¤
    return {
        "success": True,
        "response": f"{emotion_prefix}æˆ‘ç†è§£æ‚¨çš„å›°æ‰°ã€‚ä½œä¸ºå¿ƒç†åŠ©æ‰‹ï¼Œæˆ‘å»ºè®®æ‚¨å¯ä»¥æ›´è¯¦ç»†åœ°æè¿°å…·ä½“æƒ…å†µå’Œæ„Ÿå—ï¼Œè¿™æ ·æˆ‘èƒ½æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„å¸®åŠ©ã€‚",
        "detected_emotion": emotion,
        "model_source": "fallback_system",
        "timestamp": datetime.datetime.now().isoformat()
    }


def test_deepseek_api() -> Dict[str, Any]:
    """
    æµ‹è¯• DeepSeek API è¿æ¥çŠ¶æ€

    Returns:
        åŒ…å«æµ‹è¯•ç»“æœçš„å­—å…¸
    """
    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
            },
            json={
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": "test"}],
                "max_tokens": 5
            },
            timeout=10
        )

        if response.status_code == 200:
            return {"success": True, "message": "API è¿æ¥æ­£å¸¸"}
        elif response.status_code == 401:
            return {"success": False, "message": "API å¯†é’¥æ— æ•ˆ"}
        else:
            return {"success": False, "message": f"API è¿”å›é”™è¯¯: {response.status_code}"}

    except requests.exceptions.Timeout:
        return {"success": False, "message": "API è¿æ¥è¶…æ—¶"}
    except Exception as e:
        return {"success": False, "message": f"API è¿æ¥å¤±è´¥: {str(e)}"}


# ==================== TTS æ–‡å­—è½¬è¯­éŸ³æ¨¡å— ====================
def text_to_speech(text: str) -> Dict[str, Any]:
    """
    å°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³ MP3 æ–‡ä»¶

    Args:
        text: è¦è½¬æ¢çš„æ–‡å­—å†…å®¹

    Returns:
        åŒ…å«éŸ³é¢‘æ–‡ä»¶è·¯å¾„çš„å­—å…¸
    """
    try:
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        audio_filename = f"tts_{uuid.uuid4().hex[:8]}.mp3"
        audio_path = os.path.join(AUDIO_OUTPUT_DIR, audio_filename)

        logger.info(f"å¼€å§‹ TTS è½¬æ¢ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")

        # è°ƒç”¨ SiliconFlow TTS API
        request_data = {
            "model": "IndexTeam/IndexTTS-2",
            "voice": "IndexTeam/IndexTTS-2:claire",
            "stream": True,
            "input": text,
            "max_tokens": 1600,
            "response_format": "mp3",
            "speed": 1,
            "gain": 0
        }
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f"Bearer {TTS_API_TOKEN}"
        }

        response = requests.post(
            url=TTS_API_URL,
            json=request_data,
            headers=headers,
            timeout=60
        )

        if response.status_code != 200:
            logger.error(f"TTS API é”™è¯¯: {response.status_code} - {response.text[:200]}")
            return {"success": False, "error": f"TTS API é”™è¯¯: {response.status_code}"}

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        with open(audio_path, 'wb') as f:
            f.write(response.content)

        logger.info(f"TTS è½¬æ¢æˆåŠŸï¼Œä¿å­˜åˆ°: {audio_path}")
        return {
            "success": True,
            "audio_path": audio_path,
            "audio_filename": audio_filename
        }

    except requests.exceptions.Timeout:
        logger.error("TTS API è¯·æ±‚è¶…æ—¶")
        return {"success": False, "error": "TTS è¯·æ±‚è¶…æ—¶"}
    except Exception as e:
        logger.error(f"TTS è½¬æ¢å¤±è´¥: {str(e)}")
        return {"success": False, "error": str(e)}


# ==================== SadTalker è§†é¢‘ç”Ÿæˆæ¨¡å— ====================
def generate_talking_video(audio_path: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨ SadTalker ç”Ÿæˆæ•°å­—äººè¯´è¯è§†é¢‘

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶çš„ç»å¯¹è·¯å¾„

    Returns:
        åŒ…å«è§†é¢‘æ–‡ä»¶è·¯å¾„çš„å­—å…¸
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(SADTALKER_IMAGE):
            logger.error(f"æ•°å­—äººå›¾ç‰‡ä¸å­˜åœ¨: {SADTALKER_IMAGE}")
            return {"success": False, "error": "æ•°å­—äººå›¾ç‰‡ä¸å­˜åœ¨"}

        if not os.path.exists(audio_path):
            logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return {"success": False, "error": "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨"}

        logger.info("å¼€å§‹ç”Ÿæˆæ•°å­—äººè§†é¢‘...")
        logger.info(f"å›¾ç‰‡: {SADTALKER_IMAGE}")
        logger.info(f"éŸ³é¢‘: {audio_path}")

        # æ£€æµ‹ SadTalker ç›®å½•ä¸‹çš„è™šæ‹Ÿç¯å¢ƒ
        sadtalker_venv_python = os.path.join(SADTALKER_DIR, ".venv", "Scripts", "python.exe")

        if os.path.exists(sadtalker_venv_python):
            python_exec = sadtalker_venv_python
            logger.info(f"ä½¿ç”¨ SadTalker è™šæ‹Ÿç¯å¢ƒ: {sadtalker_venv_python}")
        else:
            python_exec = "python"
            logger.warning("æœªæ£€æµ‹åˆ° SadTalker/.venvï¼Œä½¿ç”¨é»˜è®¤ Python")

        # æ„å»º SadTalker å‘½ä»¤
        cmd = [
            python_exec, "inference.py",
            "--driven_audio", audio_path,
            "--source_image", SADTALKER_IMAGE,
            "--result_dir", SADTALKER_OUTPUT_DIR,
            "--still",
            "--preprocess", "crop",
            # "--enhancer", "gfpgan",
            "--batch_size", "4"
        ]

        # åœ¨ SadTalker ç›®å½•ä¸‹æ‰§è¡Œ
        process = subprocess.Popen(
            cmd,
            cwd=SADTALKER_DIR,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True
        )

        # è¯»å–è¾“å‡º
        output_lines = []
        for line in process.stdout:
            output_lines.append(line)
            logger.info(f"SadTalker: {line.strip()}")

        process.wait()

        if process.returncode != 0:
            logger.error(f"SadTalker æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
            return {"success": False, "error": "è§†é¢‘ç”Ÿæˆå¤±è´¥"}

        # æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶ï¼ˆæœ€æ–°çš„ mp4 æ–‡ä»¶ï¼‰
        video_pattern = os.path.join(SADTALKER_OUTPUT_DIR, "**", "*.mp4")
        video_files = glob.glob(video_pattern, recursive=True)

        if not video_files:
            logger.error("æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶")
            return {"success": False, "error": "æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘"}

        # è·å–æœ€æ–°çš„è§†é¢‘æ–‡ä»¶
        latest_video = max(video_files, key=os.path.getmtime)
        video_filename = os.path.basename(latest_video)

        logger.info(f"è§†é¢‘ç”ŸæˆæˆåŠŸ: {latest_video}")
        return {
            "success": True,
            "video_path": latest_video,
            "video_filename": video_filename
        }

    except Exception as e:
        logger.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
        return {"success": False, "error": str(e)}


# ==================== åˆå§‹åŒ–ä»£ç†å®ä¾‹ ====================
agent = PsychologicalAgent(DEEPSEEK_API_KEY)


# ==================== API è·¯ç”± ====================

@app.route('/')
def index():
    """
    é¦–é¡µè·¯ç”± - æä¾›å‰ç«¯é¡µé¢

    Returns:
        HTML é¡µé¢å†…å®¹
    """
    try:
        with open('index.html', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return """
        <!DOCTYPE html>
        <html>
        <head><title>å¤§å­¦ç”Ÿå¿ƒç†åˆ†ææ•°å­—äººä»£ç†</title></head>
        <body style="font-family: Arial; padding: 40px; text-align: center;">
            <h1 style="color: #4a90e2;">å¤§å­¦ç”Ÿå¿ƒç†åˆ†ææ•°å­—äººä»£ç†</h1>
            <p>ç³»ç»Ÿæ­£åœ¨è¿è¡Œï¼Œä½† index.html æ–‡ä»¶æœªæ‰¾åˆ°</p>
            <p>API æµ‹è¯•ï¼š<a href="/api/health">/api/health</a></p>
        </body>
        </html>
        """


@app.route('/api/analyze', methods=['POST'])
def analyze():
    """
    å¿ƒç†åˆ†æä¸»æ¥å£ï¼ˆé›†æˆ TTS å’Œæ•°å­—äººè§†é¢‘ç”Ÿæˆï¼‰

    è¯·æ±‚ä½“:
        - message: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
        - detected_emotion: æ£€æµ‹åˆ°çš„æƒ…ç»ªï¼ˆå¯é€‰ï¼‰
        - generate_video: æ˜¯å¦ç”Ÿæˆæ•°å­—äººè§†é¢‘ï¼ˆå¯é€‰ï¼Œé»˜è®¤ Trueï¼‰

    Returns:
        JSON æ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«è§†é¢‘ URL
    """
    try:
        data = request.get_json()
        user_input = data.get('message', '').strip()
        detected_emotion = data.get('detected_emotion', 'neutral')
        generate_video = data.get('generate_video', True)

        logger.info(f"æ”¶åˆ°åˆ†æè¯·æ±‚ - æƒ…ç»ª: {detected_emotion}, ç”Ÿæˆè§†é¢‘: {generate_video}")

        if not user_input:
            return jsonify({"success": False, "error": "è¾“å…¥ä¸èƒ½ä¸ºç©º"}), 400

        # è°ƒç”¨å¿ƒç†åˆ†æä»£ç†
        result = agent.analyze(user_input, detected_emotion)

        if result["success"]:
            result["detected_emotion"] = detected_emotion
            result["timestamp"] = datetime.datetime.now().isoformat()

            # å¦‚æœéœ€è¦ç”Ÿæˆè§†é¢‘
            if generate_video:
                response_text = result.get("response", "")

                # æ¸…ç† HTML æ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬ç”¨äº TTS
                import re
                clean_text = re.sub(r'<[^>]+>', '', response_text)
                clean_text = clean_text.replace('<br>', 'ã€‚').replace('&nbsp;', ' ')

                # æ­¥éª¤1: TTS æ–‡å­—è½¬è¯­éŸ³
                logger.info("å¼€å§‹ TTS è½¬æ¢...")
                tts_result = text_to_speech(clean_text)

                if tts_result["success"]:
                    audio_path = tts_result["audio_path"]
                    result["audio_url"] = f"/api/audio/{tts_result['audio_filename']}"

                    # æ­¥éª¤2: SadTalker ç”Ÿæˆè§†é¢‘
                    logger.info("å¼€å§‹ç”Ÿæˆæ•°å­—äººè§†é¢‘...")
                    video_result = generate_talking_video(audio_path)

                    if video_result["success"]:
                        result["video_url"] = f"/api/video/{video_result['video_filename']}"
                        result["video_generated"] = True
                        logger.info(f"è§†é¢‘ç”ŸæˆæˆåŠŸ: {video_result['video_filename']}")
                    else:
                        result["video_generated"] = False
                        result["video_error"] = video_result.get("error", "è§†é¢‘ç”Ÿæˆå¤±è´¥")
                        logger.warning(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {video_result.get('error')}")
                else:
                    result["video_generated"] = False
                    result["tts_error"] = tts_result.get("error", "TTS è½¬æ¢å¤±è´¥")
                    logger.warning(f"TTS è½¬æ¢å¤±è´¥: {tts_result.get('error')}")

        return jsonify(result)

    except Exception as e:
        logger.error(f"åˆ†ææ¥å£é”™è¯¯: {str(e)}")
        return jsonify({"success": False, "error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500


@app.route('/api/video/<filename>')
def serve_video(filename):
    """
    æä¾›è§†é¢‘æ–‡ä»¶æœåŠ¡

    Args:
        filename: è§†é¢‘æ–‡ä»¶å

    Returns:
        è§†é¢‘æ–‡ä»¶
    """
    # åœ¨ SadTalker è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘
    video_pattern = os.path.join(SADTALKER_OUTPUT_DIR, "**", filename)
    video_files = glob.glob(video_pattern, recursive=True)

    if video_files:
        video_path = video_files[0]
        directory = os.path.dirname(video_path)
        return send_from_directory(directory, filename, mimetype='video/mp4')

    logger.error(f"è§†é¢‘æ–‡ä»¶æœªæ‰¾åˆ°: {filename}")
    return jsonify({"error": "è§†é¢‘æ–‡ä»¶æœªæ‰¾åˆ°"}), 404


@app.route('/api/audio/<filename>')
def serve_audio(filename):
    """
    æä¾›éŸ³é¢‘æ–‡ä»¶æœåŠ¡

    Args:
        filename: éŸ³é¢‘æ–‡ä»¶å

    Returns:
        éŸ³é¢‘æ–‡ä»¶
    """
    audio_path = os.path.join(AUDIO_OUTPUT_DIR, filename)

    if os.path.exists(audio_path):
        return send_from_directory(AUDIO_OUTPUT_DIR, filename, mimetype='audio/mpeg')

    logger.error(f"éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°: {filename}")
    return jsonify({"error": "éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°"}), 404


@app.route('/api/analyze_local', methods=['POST'])
def analyze_local():
    """
    æœ¬åœ°æ¨¡å‹åˆ†ææ¥å£ï¼ˆå½“å‰ä½¿ç”¨ DeepSeek API ä½œä¸ºåå¤‡ï¼‰

    è¯·æ±‚ä½“:
        - message: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
        - detected_emotion: æ£€æµ‹åˆ°çš„æƒ…ç»ªï¼ˆå¯é€‰ï¼‰

    Returns:
        JSON æ ¼å¼çš„åˆ†æç»“æœ
    """
    try:
        data = request.get_json()
        user_input = data.get('message', '').strip()
        detected_emotion = data.get('detected_emotion', 'neutral')

        logger.info(f"æ”¶åˆ°æœ¬åœ°åˆ†æè¯·æ±‚ - æƒ…ç»ª: {detected_emotion}")

        if not user_input:
            return jsonify({"success": False, "error": "è¾“å…¥ä¸èƒ½ä¸ºç©º"}), 400

        # å°è¯•ä½¿ç”¨ DeepSeek API
        result = agent.analyze(user_input, detected_emotion)

        if result["success"]:
            result["detected_emotion"] = detected_emotion
            result["timestamp"] = datetime.datetime.now().isoformat()
        else:
            # API å¤±è´¥æ—¶ä½¿ç”¨å¤‡é€‰å›å¤
            result = generate_fallback_response(user_input, detected_emotion)

        return jsonify(result)

    except Exception as e:
        logger.error(f"æœ¬åœ°åˆ†ææ¥å£é”™è¯¯: {str(e)}")
        return jsonify({"success": False, "error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500


@app.route('/api/analyze_emotion', methods=['POST'])
def analyze_emotion():
    """
    è¡¨æƒ…è¯†åˆ«æ¥å£

    è¯·æ±‚ä½“:
        - image: Base64 ç¼–ç çš„å›¾åƒæ•°æ®

    Returns:
        JSON æ ¼å¼çš„æƒ…ç»ªåˆ†æç»“æœ
    """
    try:
        data = request.get_json()

        if not data or 'image' not in data:
            return jsonify({"success": False, "error": "æ²¡æœ‰æä¾›å›¾ç‰‡æ•°æ®"}), 400

        logger.info("æ”¶åˆ°è¡¨æƒ…åˆ†æè¯·æ±‚")

        # åˆ†æè¡¨æƒ…
        result = analyze_emotion_from_image(data['image'])

        return jsonify({
            "success": True,
            "dominant_emotion": result["dominant_emotion"],
            "emotion_scores": result["emotion_scores"],
            "face_detected": result["face_detected"],
            "timestamp": datetime.datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"è¡¨æƒ…åˆ†ææ¥å£é”™è¯¯: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e),
            "dominant_emotion": "neutral",
            "emotion_scores": DEFAULT_EMOTION_SCORES.copy(),
            "face_detected": False
        }), 500


@app.route('/api/model/status', methods=['GET'])
def model_status():
    """
    æ¨¡å‹çŠ¶æ€æŸ¥è¯¢æ¥å£

    Returns:
        JSON æ ¼å¼çš„æ¨¡å‹çŠ¶æ€ä¿¡æ¯
    """
    return jsonify({
        "local_model_loaded": False,
        "model_loading": False,
        "deepface_available": DEEPFACE_AVAILABLE,
        "deepseek_api_available": True,
        "timestamp": datetime.datetime.now().isoformat()
    })


@app.route('/api/status', methods=['GET'])
def api_status():
    """
    API çŠ¶æ€æ£€æŸ¥æ¥å£

    Returns:
        JSON æ ¼å¼çš„ API çŠ¶æ€ä¿¡æ¯
    """
    api_test = test_deepseek_api()

    return jsonify({
        "status": "healthy" if api_test.get("success") else "warning",
        "deepseek_api": api_test,
        "deepface_available": DEEPFACE_AVAILABLE,
        "timestamp": datetime.datetime.now().isoformat()
    })


@app.route('/api/health', methods=['GET'])
def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£

    Returns:
        JSON æ ¼å¼çš„æœåŠ¡å¥åº·çŠ¶æ€
    """
    return jsonify({
        "status": "healthy",
        "service": "å¤§å­¦ç”Ÿå¿ƒç†åˆ†ææ•°å­—äººä»£ç†",
        "version": "2.0",
        "timestamp": datetime.datetime.now().isoformat(),
        "features": {
            "psychological_analysis": True,
            "emotion_recognition": DEEPFACE_AVAILABLE,
            "real_time_camera": True,
            "deepseek_api": True
        }
    })


@app.route('/api/conversation/summary', methods=['GET'])
def get_conversation_summary():
    """
    è·å–å¯¹è¯æ‘˜è¦

    Returns:
        JSON æ ¼å¼çš„å¯¹è¯æ‘˜è¦ä¿¡æ¯
    """
    user_messages = [msg['content'] for msg in conversation_history if msg['role'] == 'user']

    return jsonify({
        "total_conversations": len(conversation_history) // 2,
        "recent_topics": user_messages[-3:] if user_messages else [],
        "timestamp": datetime.datetime.now().isoformat()
    })


@app.route('/api/conversation/reset', methods=['POST'])
def reset_conversation():
    """
    é‡ç½®å¯¹è¯å†å²

    Returns:
        JSON æ ¼å¼çš„æ“ä½œç»“æœ
    """
    global conversation_history
    conversation_history = []
    logger.info("å¯¹è¯å†å²å·²é‡ç½®")
    return jsonify({"success": True, "message": "å¯¹è¯å·²é‡ç½®"})


@app.route('/api/debug', methods=['GET'])
def debug_info():
    """
    è°ƒè¯•ä¿¡æ¯æ¥å£ï¼ˆä»…ç”¨äºå¼€å‘ï¼‰

    Returns:
        JSON æ ¼å¼çš„è°ƒè¯•ä¿¡æ¯
    """
    return jsonify({
        "routes": [str(rule) for rule in app.url_map.iter_rules()],
        "conversation_length": len(conversation_history),
        "deepface_available": DEEPFACE_AVAILABLE,
        "api_key_set": bool(DEEPSEEK_API_KEY),
        "timestamp": datetime.datetime.now().isoformat()
    })


@app.route('/favicon.ico')
def favicon():
    """å¤„ç† favicon è¯·æ±‚ï¼Œé¿å… 404 é”™è¯¯"""
    return '', 204


# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == '__main__':
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print("=" * 60)
    print("å¤§å­¦ç”Ÿå¿ƒç†åˆ†ææ•°å­—äººä»£ç† v2.0")
    print("=" * 60)
    print(f"ğŸ“± æœåŠ¡åœ°å€: http://localhost:5000")
    print(f"â¤ï¸  å¥åº·æ£€æŸ¥: http://localhost:5000/api/health")
    print(f"ğŸ“Š æ¨¡å‹çŠ¶æ€: http://localhost:5000/api/model/status")
    print(f"ğŸ” è°ƒè¯•ä¿¡æ¯: http://localhost:5000/api/debug")
    print("=" * 60)
    print("å¯ç”¨ API ç«¯ç‚¹:")
    print("  POST /api/analyze        - å¿ƒç†åˆ†æ")
    print("  POST /api/analyze_local  - æœ¬åœ°æ¨¡å‹åˆ†æ")
    print("  POST /api/analyze_emotion - è¡¨æƒ…è¯†åˆ«")
    print("  GET  /api/health         - å¥åº·æ£€æŸ¥")
    print("  GET  /api/model/status   - æ¨¡å‹çŠ¶æ€")
    print("  GET  /api/conversation/summary - å¯¹è¯æ‘˜è¦")
    print("  POST /api/conversation/reset   - é‡ç½®å¯¹è¯")
    print("=" * 60)
    print("ğŸš€ æœåŠ¡å¯åŠ¨ä¸­...")
    print("=" * 60)

    # å¯åŠ¨ Flask æœåŠ¡
    app.run(
        debug=True,
        host='0.0.0.0',
        port=5000,
        use_reloader=False  # ç¦ç”¨è‡ªåŠ¨é‡è½½ï¼Œé¿å…æ¨¡å‹é‡å¤åŠ è½½
    )
